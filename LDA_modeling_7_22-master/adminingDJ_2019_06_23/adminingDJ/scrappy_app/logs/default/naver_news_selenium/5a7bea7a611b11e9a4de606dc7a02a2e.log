2019-04-17 23:16:20 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: scrappy_app)
2019-04-17 23:16:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.3 (v3.7.3:ef4ec6ed12, Mar 25 2019, 21:26:53) [MSC v.1916 32 bit (Intel)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Windows-10-10.0.17134-SP0
2019-04-17 23:16:20 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'scrappy_app', 'LOG_FILE': 'logs\\default\\naver_news_selenium\\5a7bea7a611b11e9a4de606dc7a02a2e.log', 'NEWSPIDER_MODULE': 'scrappy_app.spiders', 'SPIDER_MODULES': ['scrappy_app.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0'}
2019-04-17 23:16:20 [scrapy.extensions.telnet] INFO: Telnet Password: d6724d24c4495d83
2019-04-17 23:16:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-04-17 23:16:23 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:6067/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "firefox", "acceptInsecureCerts": true}}, "desiredCapabilities": {"browserName": "firefox", "acceptInsecureCerts": true, "marionette": true}}
2019-04-17 23:16:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:6067
2019-04-17 23:16:29 [urllib3.connectionpool] DEBUG: http://127.0.0.1:6067 "POST /session HTTP/1.1" 200 704
2019-04-17 23:16:29 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-04-17 23:16:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-17 23:16:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-17 23:16:29 [scrapy.middleware] INFO: Enabled item pipelines:
['scrappy_app.pipelines.NaverNewsPipeline']
2019-04-17 23:16:29 [scrapy.core.engine] INFO: Spider opened
2019-04-17 23:16:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-17 23:16:29 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-17 23:16:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://search.naver.com/search.naver?ie=utf8&where=news&query=onion&sm=tab_pge&sort=1&photo=0&field=0&pd=3&ds=&de=&qvt=0&start=> (referer: None)
2019-04-17 23:16:29 [naver_news_selenium] WARNING: http://news.mk.co.kr/v2/economy/view.php?year=2019&no=230321
2019-04-17 23:16:29 [naver_news_selenium] WARNING: https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=104&oid=077&aid=0004458494
2019-04-17 23:16:29 [naver_news_selenium] WARNING: http://www.hankookilbo.com/news/npath/201904110744752595?did=NA
2019-04-17 23:16:29 [naver_news_selenium] WARNING: http://news.donga.com/3/all/20190329/94799565/1
2019-04-17 23:16:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://news.mk.co.kr/v2/economy/view.php?year=2019&no=230321> (referer: None)
2019-04-17 23:16:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.hankookilbo.com/News/Read/201904110744752595?did=NA&dtype=&dtypecode=&prnewsid=> from <GET http://www.hankookilbo.com/news/npath/201904110744752595?did=NA>
2019-04-17 23:16:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://news.donga.com/3/all/20190329/94799565/1> (referer: None)
2019-04-17 23:16:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=104&oid=077&aid=0004458494> (referer: https://search.naver.com/search.naver?ie=utf8&where=news&query=onion&sm=tab_pge&sort=1&photo=0&field=0&pd=3&ds=&de=&qvt=0&start=)
2019-04-17 23:16:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.hankookilbo.com/News/Read/201904110744752595?did=NA&dtype=&dtypecode=&prnewsid=> (referer: None)
2019-04-17 23:16:29 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:6067/session/4b4b1a57-2f97-45c5-ba8f-68aca4ccd10f/url {"url": "http://news.mk.co.kr/v2/economy/view.php?year=2019&no=230321"}
2019-04-17 23:16:35 [urllib3.connectionpool] DEBUG: http://127.0.0.1:6067 "POST /session/4b4b1a57-2f97-45c5-ba8f-68aca4ccd10f/url HTTP/1.1" 200 14
2019-04-17 23:16:35 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-04-17 23:16:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://news.mk.co.kr/v2/economy/view.php?year=2019&no=230321> (referer: None)
Traceback (most recent call last):
  File "c:\users\teo\appdata\local\programs\python\python37-32\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\Teo\Desktop\Coding\django\adminingDJ\scrappy_app\scrappy_app\spiders\naverNewsSelenium.py", line 67, in parse
    hxs = Selector(response)
  File "c:\users\teo\appdata\local\programs\python\python37-32\lib\site-packages\scrapy\selector\unified.py", line 104, in __init__
    super(Selector, self).__init__(text=text, type=st, root=root, **kwargs)
  File "c:\users\teo\appdata\local\programs\python\python37-32\lib\site-packages\parsel\selector.py", line 195, in __init__
    raise ValueError("Selector needs either text or root argument")
ValueError: Selector needs either text or root argument
2019-04-17 23:16:35 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:6067/session/4b4b1a57-2f97-45c5-ba8f-68aca4ccd10f/url {"url": "http://news.donga.com/3/all/20190329/94799565/1"}
2019-04-17 23:16:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:6067 "POST /session/4b4b1a57-2f97-45c5-ba8f-68aca4ccd10f/url HTTP/1.1" 200 14
2019-04-17 23:16:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-04-17 23:16:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://news.donga.com/3/all/20190329/94799565/1> (referer: None)
Traceback (most recent call last):
  File "c:\users\teo\appdata\local\programs\python\python37-32\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\Teo\Desktop\Coding\django\adminingDJ\scrappy_app\scrappy_app\spiders\naverNewsSelenium.py", line 67, in parse
    hxs = Selector(response)
  File "c:\users\teo\appdata\local\programs\python\python37-32\lib\site-packages\scrapy\selector\unified.py", line 104, in __init__
    super(Selector, self).__init__(text=text, type=st, root=root, **kwargs)
  File "c:\users\teo\appdata\local\programs\python\python37-32\lib\site-packages\parsel\selector.py", line 195, in __init__
    raise ValueError("Selector needs either text or root argument")
ValueError: Selector needs either text or root argument
2019-04-17 23:16:44 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:6067/session/4b4b1a57-2f97-45c5-ba8f-68aca4ccd10f/url {"url": "https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=104&oid=077&aid=0004458494"}
2019-04-17 23:16:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:6067 "POST /session/4b4b1a57-2f97-45c5-ba8f-68aca4ccd10f/url HTTP/1.1" 200 14
2019-04-17 23:16:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-04-17 23:16:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=104&oid=077&aid=0004458494> (referer: https://search.naver.com/search.naver?ie=utf8&where=news&query=onion&sm=tab_pge&sort=1&photo=0&field=0&pd=3&ds=&de=&qvt=0&start=)
Traceback (most recent call last):
  File "c:\users\teo\appdata\local\programs\python\python37-32\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\Teo\Desktop\Coding\django\adminingDJ\scrappy_app\scrappy_app\spiders\naverNewsSelenium.py", line 67, in parse
    hxs = Selector(response)
  File "c:\users\teo\appdata\local\programs\python\python37-32\lib\site-packages\scrapy\selector\unified.py", line 104, in __init__
    super(Selector, self).__init__(text=text, type=st, root=root, **kwargs)
  File "c:\users\teo\appdata\local\programs\python\python37-32\lib\site-packages\parsel\selector.py", line 195, in __init__
    raise ValueError("Selector needs either text or root argument")
ValueError: Selector needs either text or root argument
2019-04-17 23:16:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:6067/session/4b4b1a57-2f97-45c5-ba8f-68aca4ccd10f/url {"url": "http://www.hankookilbo.com/News/Read/201904110744752595?did=NA&dtype=&dtypecode=&prnewsid="}
2019-04-17 23:16:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:6067 "POST /session/4b4b1a57-2f97-45c5-ba8f-68aca4ccd10f/url HTTP/1.1" 200 14
2019-04-17 23:16:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-04-17 23:16:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.hankookilbo.com/News/Read/201904110744752595?did=NA&dtype=&dtypecode=&prnewsid=> (referer: None)
Traceback (most recent call last):
  File "c:\users\teo\appdata\local\programs\python\python37-32\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\Teo\Desktop\Coding\django\adminingDJ\scrappy_app\scrappy_app\spiders\naverNewsSelenium.py", line 67, in parse
    hxs = Selector(response)
  File "c:\users\teo\appdata\local\programs\python\python37-32\lib\site-packages\scrapy\selector\unified.py", line 104, in __init__
    super(Selector, self).__init__(text=text, type=st, root=root, **kwargs)
  File "c:\users\teo\appdata\local\programs\python\python37-32\lib\site-packages\parsel\selector.py", line 195, in __init__
    raise ValueError("Selector needs either text or root argument")
ValueError: Selector needs either text or root argument
2019-04-17 23:16:51 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-17 23:16:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2215,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 186229,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 5,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 17, 14, 16, 51, 633049),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 4,
 'log_count/INFO': 9,
 'log_count/WARNING': 4,
 'request_depth_max': 1,
 'response_received_count': 5,
 'scheduler/dequeued': 6,
 'scheduler/dequeued/memory': 6,
 'scheduler/enqueued': 6,
 'scheduler/enqueued/memory': 6,
 'spider_exceptions/ValueError': 4,
 'start_time': datetime.datetime(2019, 4, 17, 14, 16, 29, 236871)}
2019-04-17 23:16:51 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-17 23:16:51 [selenium.webdriver.remote.remote_connection] DEBUG: DELETE http://127.0.0.1:6067/session/4b4b1a57-2f97-45c5-ba8f-68aca4ccd10f/window {}
2019-04-17 23:16:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:6067 "DELETE /session/4b4b1a57-2f97-45c5-ba8f-68aca4ccd10f/window HTTP/1.1" 200 12
2019-04-17 23:16:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-04-17 23:16:56 [selenium.webdriver.remote.remote_connection] DEBUG: DELETE http://127.0.0.1:6067/session/4b4b1a57-2f97-45c5-ba8f-68aca4ccd10f/window {}
2019-04-17 23:16:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:6067 "DELETE /session/4b4b1a57-2f97-45c5-ba8f-68aca4ccd10f/window HTTP/1.1" 404 123
2019-04-17 23:16:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
